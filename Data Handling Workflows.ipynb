{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Handling Workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries and Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using the htex configuration for Parsl. Read more [here.]( https://github.com/Parsl/parsl/blob/master/parsl/configs/htex_local.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<parsl.dataflow.dflow.DataFlowKernel at 0x1148db4d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import parsl\n",
    "import os\n",
    "from parsl.app.app import python_app, bash_app\n",
    "from parsl.configs.local_threads import config\n",
    "\n",
    "parsl.load(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A map reduce is a technique to execute multiple parallel jobs on a dataset to reduce the size of the dataset before executing a final function to get the result. A Map reduce is a more complicated version of synchronisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider a simple example where we are given multiple lists and we want to select the lists with the highest standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/map_reduce.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A python app to compute the standard deviation of the inputs\n",
    "@python_app\n",
    "def standard_deviation(inputs=[]):\n",
    "    import numpy as np\n",
    "    return np.std(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# A function to construct data that is a list of lists, each each list having 100 random numbers\n",
    "\n",
    "def make_data():\n",
    "    lists = []\n",
    "    \n",
    "    for _ in range(100):\n",
    "        new_list = []\n",
    "        \n",
    "        for __ in range(100):\n",
    "            new_list.append(random.random()*100)\n",
    "            \n",
    "        lists.append(new_list)\n",
    "    return lists\n",
    "\n",
    "our_data = make_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the standard deviations for each list\n",
    "\n",
    "standard_deviations = []\n",
    "\n",
    "for i in our_data:\n",
    "    standard_deviations.append(standard_deviation(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Standard Deviation:  31.95613285570822\n"
     ]
    }
   ],
   "source": [
    "# Finding the maximum standard deviation\n",
    "\n",
    "standard_deviations = [i.result() for i in standard_deviations]\n",
    "print('Maximum Standard Deviation: ', max(standard_deviations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target List Number: 40\n"
     ]
    }
   ],
   "source": [
    "# Finding the list with the maximum standard deviation\n",
    "\n",
    "maximum = max(standard_deviations)\n",
    "print('Target List Number:', standard_deviations.index(maximum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using a simple hash function to store elements in our database. We'll evaluate the hash values in parallel and then store the items in those locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = [0 for i in range(1000)]  # An empty database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@python_app \n",
    "def hash_function(element, database):\n",
    "    import hashlib\n",
    "    number = int(hashlib.md5(element).hexdigest()[:8], 16)%1000   # Creating a hash index\n",
    "    database[number] = element # Storing it in the database based on the hashed index\n",
    "    return database # return the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "elements = []\n",
    "\n",
    "for i in range(100):\n",
    "    element = '' \n",
    "    for _ in range(5):\n",
    "        element += random.choice('abcdefghijklmopqrstuvwxyz')\n",
    "    element = element.encode() # Making a 5 letter element\n",
    "    elements.append(element) # collecting 100 such elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in elements: # Updating the database for all the elements\n",
    "    database = hash_function(i, database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, b'gwpde', 0, b'gchcx', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, b'rqwik', 0, 0, 0, 0, b'xuthu', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, b'zbbvc', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, b'bcrfc', 0, 0, b'frulk', 0, b'qaqkd', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, b'akybt', 0, 0, 0, b'ytbfd', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, b'hbpiy', 0, b'zgvpq', 0, 0, 0, 0, b'remuf', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, b'tirle', 0, b'rckyk', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, b'qhtww', 0, 0, 0, 0, 0, b'zpsjd', 0, 0, 0, 0, 0, 0, b'mjfhw', 0, 0, 0, 0, 0, b'wsdyh', 0, 0, 0, 0, 0, 0, 0, 0, 0, b'hwqoq', 0, 0, 0, b'ggaxd', 0, 0, 0, b'jlhwc', 0, 0, b'yglvu', 0, 0, 0, 0, 0, 0, 0, 0, b'ftxpc', 0, b'gseqq', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, b'fotsw', 0, 0, 0, b'qswiq', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, b'vdxoo', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, b'xayrz', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, b'igjhy', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, b'zmtos', 0, 0, 0, 0, 0, 0, b'berve', 0, 0, 0, 0, 0, b'kbmvs', 0, 0, 0, b'dhmfl', b'tozyi', 0, 0, 0, 0, b'kyafk', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, b'yqoug', 0, 0, 0, 0, 0, b'bxlht', 0, 0, 0, 0, 0, 0, b'uyvjg', b'hdkbc', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, b'pcssk', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, b'lmhtx', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, b'vjpya', 0, 0, 0, 0, 0, 0, b'fsijs', 0, 0, 0, 0, 0, b'asiiq', 0, 0, 0, 0, 0, 0, 0, b'byykt', 0, 0, b'ahhak', 0, 0, 0, 0, 0, 0, b'whyzf', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, b'safav', 0, 0, 0, 0, 0, 0, 0, b'ieeba', 0, b'bgowu', 0, 0, 0, b'wxxqe', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, b'pdhdg', 0, 0, b'edyxu', 0, b'emjgc', b'zfqei', 0, 0, 0, b'yaarz', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, b'tvxab', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, b'pbjaw', 0, 0, 0, 0, 0, b'lexmr', 0, 0, 0, b'ldahm', 0, b'kymmq', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, b'iszuq', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, b'dscdk', b'sgdxc', 0, 0, 0, 0, 0, 0, 0, 0, 0, b'dzqjy', 0, 0, b'oduri', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, b'scttd', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, b'syppm', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, b'zfmhp', b'dvckv', 0, 0, 0, 0, 0, b'stzij', 0, 0, 0, 0, 0, b'ovywc', 0, 0, 0, 0, 0, 0, 0, 0, b'fdujc', 0, 0, b'hjxpo', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, b'rcaop', 0, 0, 0, 0, 0, 0, b'msxrw', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, b'mhfsf', 0, 0, 0, 0, 0, b'giyeq', 0, 0, 0, 0, 0, 0, b'grmjh', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, b'efbmg', 0, 0, 0, 0, b'zarib', 0, b'dcrbi', 0, 0, 0, 0, 0, 0, 0, 0, b'hwreg', 0, 0, 0, 0, 0, b'hhbdh', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, b'idspi', 0, 0, 0, 0, b'hdfye', 0, 0, 0, 0, 0, 0, b'wbpmw', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, b'ejhci', 0, 0, 0, b'kfmgd', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, b'ypjqg', 0, 0, 0, b'btzdk', 0, b'ojxuh', 0, 0, 0, 0, 0, 0, 0, 0, b'igdtf', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, b'yocsd', 0, 0, 0, b'vwosr', 0, 0, 0, 0, 0, 0, 0, b'hfovx', 0, 0, 0, 0, 0, b'lhbeu', 0]\n"
     ]
    }
   ],
   "source": [
    "print(database.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this still doesn't solve the problem of overlap of elements. Chaining is the alternative here but in order to implement chaining, we have to evaluate the results which breaks the parallel thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
