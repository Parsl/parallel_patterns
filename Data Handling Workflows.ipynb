{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Handling Workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Note that Parsl is not effective if multiple CPU cores aren't available because Parsl's ability to execute tasks in parallel is depenedent on the availability multiple cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cores available: 4\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "print('Cores available: {}'.format(multiprocessing.cpu_count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<parsl.dataflow.dflow.DataFlowKernel at 0x118da8d90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "import parsl\n",
    "import os\n",
    "import montage_wrapper as montage\n",
    "from parsl.data_provider.files import File\n",
    "cwd = os.getcwd()\n",
    "\n",
    "from parsl.app.app import python_app, bash_app\n",
    "from parsl.providers import LocalProvider\n",
    "from parsl.channels import LocalChannel\n",
    "\n",
    "from parsl.config import Config\n",
    "from parsl.executors import HighThroughputExecutor\n",
    "\n",
    "config = Config(\n",
    "    executors=[\n",
    "        HighThroughputExecutor(\n",
    "            label=\"htex_local\",\n",
    "            cores_per_worker=1,\n",
    "            provider=LocalProvider(\n",
    "                channel=LocalChannel(),\n",
    "                init_blocks=1,\n",
    "                max_blocks=1,\n",
    "            ),\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "parsl.load(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A map reduce is a technique to execute multiple parallel jobs on a dataset to reduce the size of the dataset before executing a final function to get the result. A Map reduce is a more complicated version of synchronisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider a simple example where we are given multiple lists and we want to select the lists with the highest standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/map_reduce.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@python_app\n",
    "def standard_deviation(inputs=[]):\n",
    "    '''\n",
    "    A python app to compute the standard deviation of the inputs\n",
    "    '''\n",
    "    import numpy as np\n",
    "    return np.std(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data():\n",
    "    '''\n",
    "    A function to construct data that is a list of lists, each each list having 100 random numbers.\n",
    "    '''\n",
    "    lists = []\n",
    "    \n",
    "    for _ in range(100):\n",
    "        new_list = []\n",
    "        \n",
    "        for __ in range(100):\n",
    "            new_list.append(random.random()*100)\n",
    "            \n",
    "        lists.append(new_list)\n",
    "    return lists\n",
    "\n",
    "our_data = make_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Standard Deviation:  31.65997545363917\n",
      "Target List Number: 44\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Computing the standard deviations for each list\n",
    "'''\n",
    "\n",
    "start1 = time.time()\n",
    "\n",
    "standard_deviations = []\n",
    "\n",
    "for i in our_data:\n",
    "    standard_deviations.append(standard_deviation(inputs=i))\n",
    "\n",
    "'''\n",
    "Finding the maximum standard deviation\n",
    "'''\n",
    "\n",
    "standard_deviations = [i.result() for i in standard_deviations]\n",
    "print('Maximum Standard Deviation: ', max(standard_deviations))\n",
    "\n",
    "'''\n",
    "Finding the list with the maximum standard deviation\n",
    "'''\n",
    "\n",
    "maximum = max(standard_deviations)\n",
    "print('Target List Number:', standard_deviations.index(maximum))\n",
    "\n",
    "end1 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using a simple hash function to store elements in our database. We'll evaluate the hash values in parallel and then store the items in those locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "An empty database\n",
    "'''\n",
    "database = [0 for i in range(1000)]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@python_app \n",
    "def hash_function(element):\n",
    "    '''\n",
    "    We import the haslib library and then create the hash index.\n",
    "    '''\n",
    "    \n",
    "    import hashlib\n",
    "    number = int(hashlib.md5(element).hexdigest()[:8], 16)%1000\n",
    "    return number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Parallel Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "elements = []\n",
    "\n",
    "for i in range(100):\n",
    "    '''\n",
    "    Making a 5 letter element and collecting 100 such elements.\n",
    "    '''\n",
    "    element = '' \n",
    "    for _ in range(5):\n",
    "        element += random.choice('abcdefghijklmopqrstuvwxyz')\n",
    "    element = element.encode()\n",
    "    elements.append(element)\n",
    "\n",
    "start1 = time.time()   \n",
    "hashes = []\n",
    "for i in elements:\n",
    "    '''\n",
    "    Updating the database for all the elements.\n",
    "    '''\n",
    "    hashes.append(hash_function(i))\n",
    "\n",
    "hashes = [i.result() for i in hashes]\n",
    "\n",
    "for i in range(len(elements)):\n",
    "    database[hashes[i]] = elements[i]\n",
    "\n",
    "end1 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this still doesn't solve the problem of overlap of elements. Chaining is the alternative here but in order to implement chaining, we have to evaluate the results which breaks the parallel thread."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Montage Mosaic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python script has been inspired from the [Montage Wrapper Documentation](https://montage-wrapper.readthedocs.io/en/v0.9.5) and the [tutorial](http://montage.ipac.caltech.edu/docs/first_mosaic_tutorial.html) for the Montage Mosaic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.utils import io\n",
    "\n",
    "with io.capture_output() as captured: \n",
    "    '''\n",
    "    Packaging all the non-parallel commands inside a captured output to prevent printing any outputs here.\n",
    "    '''\n",
    "    !tar xvf Kimages.tar\n",
    "    montage.mImgtbl(os.path.join(cwd,'Kimages/'),  File(os.path.join(cwd,'Kimages.tbl')))\n",
    "    montage.mMakeHdr(File(os.path.join(cwd,'Kimages.tbl')), File(os.path.join(cwd,'Ktemplate.hdr')))\n",
    "    os.mkdir(os.path.join(cwd,'Kprojdir/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of mProfExec in Parsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@python_app\n",
    "def mProject_parsl(inputs=  [], outputs = []):\n",
    "    '''\n",
    "    This is the Parsl Function that executes the mProject on each input image \n",
    "    and outputs the FITS file to the Kprojdir directory.\n",
    "    '''\n",
    "    import montage_wrapper as montage\n",
    "    return montage.mProject(inputs[0], outputs[0], inputs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_images = os.listdir(os.path.join(cwd,'Kimages/'))\n",
    "\n",
    "output = []\n",
    "\n",
    "for image in list_of_images:\n",
    "    '''\n",
    "    For each image, we capture the input image and output image.\n",
    "    We also feed the template header for each image.\n",
    "    The inputs and outputs are then fed into the Parsl function\n",
    "    '''\n",
    "    input_image = File(os.path.join(cwd, 'Kimages/' + image))\n",
    "    output_image = File(os.path.join(cwd, 'Kprojdir/hdu0_' + image))\n",
    "    template = File(os.path.join(cwd,'Ktemplate.hdr'))\n",
    "\n",
    "    output.append(mProject_parsl(inputs=[input_image, template],\n",
    "                                 outputs = [output_image]))\n",
    "    \n",
    "output = [i.result() for i in output]\n",
    "    \n",
    "'''\n",
    "If the function wasn't run in parallel, it would have looked like this:\n",
    "\n",
    "montage.mProjExec(File(os.path.join(cwd,'Kimages.tbl')),\n",
    "                  File(os.path.join(cwd,'Ktemplate.hdr')),\n",
    "                  os.path.join(cwd,'Kprojdir/'),\n",
    "                  File(os.path.join(cwd,'stats.tbl')))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final non-parallel section of the First part of Montage Mosaic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with io.capture_output() as captured2:\n",
    "    '''\n",
    "    Packaging all the non-parallel commands inside a captured output to prevent printing any outputs here.\n",
    "    '''\n",
    "    montage.mImgtbl(os.path.join(cwd,'Kprojdir/'), File(os.path.join(cwd,'images.tbl')))\n",
    "    montage.mAdd( File(os.path.join(cwd,'images.tbl')), \n",
    "                  File(os.path.join(cwd,'Ktemplate.hdr')), \n",
    "                  File(os.path.join(cwd,'m17_uncorrected.fits')))\n",
    "    !mViewer -ct 1 -gray m17_uncorrected.fits -1s max gaussian-log -out m17_uncorrected.png\n",
    "\n",
    "'''\n",
    "The markdown image below pulls the uncorrected image file:  m17_uncorrected.png\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/m17_uncorrected.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial non-parallel section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with io.capture_output() as captured:\n",
    "    '''\n",
    "    Packaging all the non-parallel commands inside a captured output to prevent printing any outputs here.\n",
    "    '''\n",
    "    montage.mOverlaps(File(os.path.join(cwd,'images.tbl')), File(os.path.join(cwd,'diffs.tbl')))\n",
    "    os.mkdir(os.path.join(cwd,'diffdir/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of mDiffExec in Parsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@python_app\n",
    "def mDiff_parsl(inputs=[], outputs = []):\n",
    "    '''\n",
    "    The Parsl function for evaluating mDiff function over all input images.\n",
    "    This replaces the mDiffExec function.\n",
    "    '''\n",
    "\n",
    "    import montage_wrapper as montage\n",
    "    return montage.mDiff(inputs[0], inputs[1], outputs[0], inputs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This cell involves essential data processing that is required to \n",
    "feed individual images into the Parsl function for mDiff.\n",
    "\n",
    "We extract the the two images for each file (normal image and _area image).\n",
    "We laso extract the output image directory.\n",
    "'''\n",
    "\n",
    "df = pd.read_csv('diffs.tbl', comment='#', delim_whitespace=True).drop(0)\n",
    "images1 = list(df['|.1'])\n",
    "images2 = list(df['cntr2'])\n",
    "outputs = list(df['|.2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_2 = []\n",
    "\n",
    "for i in range(len(images1)):\n",
    "    '''\n",
    "    In the for loop, we extract individual input images along with output_file directory.\n",
    "    The inputs along with the template header are fed into the mDiff_parsl function.\n",
    "    '''\n",
    "    \n",
    "    image1 = File(os.path.join(cwd,'Kprojdir/' + images1[i]))\n",
    "    image2 = File(os.path.join(cwd,'Kprojdir/' + images2[i]))\n",
    "    output_file = File(os.path.join(cwd,'diffdir/' + outputs[i]))\n",
    "    template = File(os.path.join(cwd,'Ktemplate.hdr'))\n",
    "    \n",
    "    outputs_2.append(mDiff_parsl(inputs=[image1, image2, template],\n",
    "                                 outputs = [output_file]))\n",
    "    \n",
    "outputs_2 = [i.result() for i in outputs_2]\n",
    "\n",
    "'''\n",
    "If the function wasn't run in parallel, it would have looked like this:\n",
    "\n",
    "montage.mDiffExec(File(os.path.join(cwd,'diffs.tbl')), \n",
    "                  File(os.path.join(cwd,'Ktemplate.hdr')), \n",
    "                  os.path.join(cwd,'diffdir/'),\n",
    "                  proj_dir=os.path.join(cwd,'Kprojdir/'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-parallel components after mDiffExec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with io.capture_output() as captured:\n",
    "    '''\n",
    "    Packaging all the non-parallel commands inside a captured output to prevent printing any outputs here.\n",
    "    '''\n",
    "    montage.mFitExec(File(os.path.join(cwd,'diffs.tbl')), File(os.path.join(cwd,'fits.tbl')), \n",
    "                     os.path.join(cwd,'diffdir/'))\n",
    "    montage.mBgModel(File(os.path.join(cwd,'images.tbl')), File(os.path.join(cwd,'fits.tbl')), \n",
    "                 File(os.path.join(cwd,'corrections.tbl')))\n",
    "    \n",
    "    os.mkdir(os.path.join(cwd,'corrdir'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of mBgExec in Parsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This cell involves essential data processing that is required to \n",
    "feed individual images into the Parsl function for mBackground.\n",
    "\n",
    "We extract the correction values for each image along with image id that we'll use for matching each image.\n",
    "We also get the image table to get the directory of each image\n",
    "'''\n",
    "\n",
    "\n",
    "corrections = pd.read_csv('corrections.tbl', comment='|', delim_whitespace=True)\n",
    "corrections.loc[90] = list(corrections.columns)\n",
    "corrections.columns = ['id','a','b','c']\n",
    "\n",
    "for i in range(len(corrections)):\n",
    "    corrections['id'][i] = int(corrections['id'][i])\n",
    "    \n",
    "images_table = pd.read_csv('images.tbl', comment='|', delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@python_app\n",
    "def mBackground_parsl(inputs=[], outputs = []):\n",
    "    '''\n",
    "    The Parsl function for evaluating mBackground function over all input images and correct them.\n",
    "    This replaces the mBgExec function.\n",
    "    '''\n",
    "    import montage_wrapper as montage\n",
    "    return montage.mBackground( inputs[0], \n",
    "                                outputs[0], \n",
    "                                inputs[1],\n",
    "                                inputs[2],\n",
    "                                inputs[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_mb = []\n",
    "\n",
    "for i in range(len(images_table)):\n",
    "    '''\n",
    "    In the for loop, we extract individual input images along with output_image directory.\n",
    "    The inputs along with the correction values are fed into the mBackground_parsl function.\n",
    "    '''\n",
    "    \n",
    "    input_image = list(images_table['fitshdr'])[i]\n",
    "    file_name = (list(images_table['fitshdr'])[i]).replace(cwd + '/Kprojdir/', '')\n",
    "    output_image = os.path.join(cwd + '/corrdir',file_name)\n",
    "    correction_values = list(corrections.loc[ corrections['id'] == i ].values[0])\n",
    "    outputs_mb.append(mBackground_parsl(inputs = [File(input_image), correction_values[1], correction_values[2], correction_values[3]],\n",
    "                        outputs = [File(output_image)]))\n",
    "    \n",
    "outputs_mb = [i.result() for i in outputs_mb]\n",
    "\n",
    "'''\n",
    "If the function wasn't run in parallel, it would have looked like this:\n",
    "\n",
    "montage.mBgExec( File(os.path.join(cwd,'images.tbl')), \n",
    "                 File(os.path.join(cwd,'corrections.tbl')), \n",
    "                 os.path.join(cwd,'corrdir'), \n",
    "                 proj_dir=os.path.join(cwd,'Kprojdir'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final non-parallel component of the Montage Mosaic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with io.capture_output() as captured:\n",
    "    '''\n",
    "    Packaging all the non-parallel commands inside a captured output to prevent printing any outputs here.\n",
    "    '''\n",
    "    montage.mAdd(File(os.path.join(cwd,'images.tbl')), \n",
    "             File(os.path.join(cwd,'Ktemplate.hdr')), \n",
    "             File(os.path.join(cwd,'m17.fits')))\n",
    "    !mViewer -ct 1 -gray m17.fits -1s max gaussian-log -out m17.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/m17.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
