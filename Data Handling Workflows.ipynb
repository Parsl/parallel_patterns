{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Handling Workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<parsl.dataflow.dflow.DataFlowKernel at 0x7f6143073f98>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "import parsl\n",
    "import os\n",
    "from parsl.app.app import python_app, bash_app\n",
    "from parsl.providers import LocalProvider\n",
    "from parsl.channels import LocalChannel\n",
    "\n",
    "from parsl.config import Config\n",
    "from parsl.executors import HighThroughputExecutor\n",
    "\n",
    "config = Config(\n",
    "    executors=[\n",
    "        HighThroughputExecutor(\n",
    "            label=\"htex_local\",\n",
    "            cores_per_worker=1,\n",
    "            provider=LocalProvider(\n",
    "                channel=LocalChannel(),\n",
    "                init_blocks=1,\n",
    "                max_blocks=1,\n",
    "            ),\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "parsl.load(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A map reduce is a technique to execute multiple parallel jobs on a dataset to reduce the size of the dataset before executing a final function to get the result. A Map reduce is a more complicated version of synchronisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider a simple example where we are given multiple lists and we want to select the lists with the highest standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/map_reduce.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A python app to compute the standard deviation of the inputs\n",
    "@python_app\n",
    "def standard_deviation(inputs=[]):\n",
    "    import numpy as np\n",
    "    return np.std(inputs)\n",
    "\n",
    "def standard_deviation_non_p(inputs=[]):\n",
    "    import numpy as np\n",
    "    return np.std(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to construct data that is a list of lists, each each list having 100 random numbers\n",
    "\n",
    "def make_data():\n",
    "    lists = []\n",
    "    \n",
    "    for _ in range(100):\n",
    "        new_list = []\n",
    "        \n",
    "        for __ in range(100):\n",
    "            new_list.append(random.random()*100)\n",
    "            \n",
    "        lists.append(new_list)\n",
    "    return lists\n",
    "\n",
    "our_data = make_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Standard Deviation:  32.32080281855521\n",
      "Target List Number: 76\n"
     ]
    }
   ],
   "source": [
    "# Computing the standard deviations for each list\n",
    "\n",
    "start1 = time.time()\n",
    "\n",
    "standard_deviations = []\n",
    "\n",
    "for i in our_data:\n",
    "    standard_deviations.append(standard_deviation(inputs=i))\n",
    "\n",
    "# Finding the maximum standard deviation\n",
    "standard_deviations = [i.result() for i in standard_deviations]\n",
    "print('Maximum Standard Deviation: ', max(standard_deviations))\n",
    "\n",
    "# Finding the list with the maximum standard deviation\n",
    "maximum = max(standard_deviations)\n",
    "print('Target List Number:', standard_deviations.index(maximum))\n",
    "\n",
    "end1 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Parallel Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Standard Deviation:  32.32080281855521\n",
      "Target List Number: 76\n"
     ]
    }
   ],
   "source": [
    "start2 = time.time()\n",
    "\n",
    "standard_deviations = []\n",
    "\n",
    "for i in our_data:\n",
    "    standard_deviations.append(standard_deviation_non_p(inputs=i))\n",
    "\n",
    "# Finding the maximum standard deviation\n",
    "print('Maximum Standard Deviation: ', max(standard_deviations))\n",
    "\n",
    "# Finding the list with the maximum standard deviation\n",
    "maximum = max(standard_deviations)\n",
    "print('Target List Number:', standard_deviations.index(maximum))\n",
    "\n",
    "end2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken with Parsl: 0.5836498737335205\n",
      "Time taken without Parsl: 0.010065078735351562\n"
     ]
    }
   ],
   "source": [
    "print('Time taken with Parsl: {}'.format(end1-start1))\n",
    "print('Time taken without Parsl: {}'.format(end2-start2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using a simple hash function to store elements in our database. We'll evaluate the hash values in parallel and then store the items in those locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = [0 for i in range(1000)]  # An empty database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@python_app \n",
    "def hash_function(element):\n",
    "    import hashlib\n",
    "    number = int(hashlib.md5(element).hexdigest()[:8], 16)%1000   # Creating a hash index\n",
    "    return number\n",
    "    \n",
    "def hash_function_non_p(element):\n",
    "    import hashlib\n",
    "    number = int(hashlib.md5(element).hexdigest()[:8], 16)%1000   # Creating a hash index\n",
    "    return number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Parallel Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "database2 = database.copy()\n",
    "\n",
    "import random\n",
    "\n",
    "elements = []\n",
    "\n",
    "for i in range(100):\n",
    "    element = '' \n",
    "    for _ in range(5):\n",
    "        element += random.choice('abcdefghijklmopqrstuvwxyz')\n",
    "    element = element.encode() # Making a 5 letter element\n",
    "    elements.append(element) # collecting 100 such elements\n",
    "\n",
    "start1 = time.time()   \n",
    "hashes = []\n",
    "for i in elements: # Updating the database for all the elements\n",
    "    hashes.append(hash_function(i))\n",
    "\n",
    "hashes = [i.result() for i in hashes]\n",
    "\n",
    "for i in range(len(elements)):\n",
    "    database[hashes[i]] = elements[i]\n",
    "\n",
    "end1 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Non-Parallel Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "start2 = time.time()\n",
    "    \n",
    "hashes = []\n",
    "for i in elements: # Updating the database for all the elements\n",
    "    hashes.append(hash_function_non_p(i))\n",
    "\n",
    "for i in range(len(elements)):\n",
    "    database2[hashes[i]] = elements[i]\n",
    "\n",
    "end2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken with Parsl: 0.5361638069152832\n",
      "Time taken without Parsl: 0.0007882118225097656\n"
     ]
    }
   ],
   "source": [
    "print('Time taken with Parsl: {}'.format(end1-start1))\n",
    "print('Time taken without Parsl: {}'.format(end2-start2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this still doesn't solve the problem of overlap of elements. Chaining is the alternative here but in order to implement chaining, we have to evaluate the results which breaks the parallel thread."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Montage Mosaic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "from parsl.data_provider.files import File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import montage_wrapper as montage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!tar xvf Kimages.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage.mImgtbl(os.path.join(cwd,'Kimages/'),\n",
    "                File(os.path.join(cwd,'Kimages.tbl')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage.mMakeHdr(File(os.path.join(cwd,'Kimages.tbl')),\n",
    "                 File(os.path.join(cwd,'Ktemplate.hdr')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(os.path.join(cwd,'Kprojdir/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage.mProjExec(File(os.path.join(cwd,'Kimages.tbl')),\n",
    "                  File(os.path.join(cwd,'Ktemplate.hdr')),\n",
    "                  os.path.join(cwd,'Kprojdir/'),\n",
    "                  File(os.path.join(cwd,'stats.tbl')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage.mImgtbl(os.path.join(cwd,'Kprojdir/'),\n",
    "                File(os.path.join(cwd,'images.tbl')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage.mAdd( File(os.path.join(cwd,'images.tbl')), \n",
    "              File(os.path.join(cwd,'Ktemplate.hdr')), \n",
    "              File(os.path.join(cwd,'m17_uncorrected.fits')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mViewer -ct 1 -gray m17_uncorrected.fits -1s max gaussian-log -out m17_uncorrected.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/m17_uncorrected.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage.mOverlaps(File(os.path.join(cwd,'images.tbl')),\n",
    "                  File(os.path.join(cwd,'diffs.tbl')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(os.path.join(cwd,'diffdir/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage.mDiffExec(File(os.path.join(cwd,'diffs.tbl')), \n",
    "                  File(os.path.join(cwd,'Ktemplate.hdr')), \n",
    "                  os.path.join(cwd,'diffdir/'),\n",
    "                  proj_dir=os.path.join(cwd,'Kprojdir/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage.mFitExec(File(os.path.join(cwd,'diffs.tbl')), \n",
    "                 File(os.path.join(cwd,'fits.tbl')), \n",
    "                 os.path.join(cwd,'diffdir/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage.mBgModel(File(os.path.join(cwd,'images.tbl')), \n",
    "                 File(os.path.join(cwd,'fits.tbl')), \n",
    "                 File(os.path.join(cwd,'corrections.tbl')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(os.path.join(cwd,'corrdir'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage.mBgExec(File(os.path.join(cwd,'images.tbl')), \n",
    "                File(os.path.join(cwd,'corrections.tbl')), \n",
    "                os.path.join(cwd,'corrdir'), \n",
    "                proj_dir=os.path.join(cwd,'Kprojdir'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage.mAdd(File(os.path.join(cwd,'images.tbl')), \n",
    "             File(os.path.join(cwd,'Ktemplate.hdr')), \n",
    "             File(os.path.join(cwd,'m17.fits')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mViewer -ct 1 -gray m17.fits -1s max gaussian-log -out m17.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/m17.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
